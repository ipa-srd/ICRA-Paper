\section{Experimental results}
\label{sec:Experiment}

\subsection{Classification of laser data}

In order to evaluate the leg detector, the robot was set up in a corridor, recording legs of people passing through over a course of three hours. Walls were separated from the passage, which results in labeled laser measurements, which are compared to the detector in order to evaluate its accuracy. The leg detector receives the input from the laser scan and labels each point as leg or non-leg.
In the comparison to the ground truth, we find, that the detector works best in close range, while becoming weaker as the range increases. This is demonstrated in Figure \ref{fig:radius_detection}, where a short, 100 second long exposure was analyzed.

The decrease in the first half originates mainly from the difficulty of interpreting the laser data, as the points spread further out depending on the distance to the scanner. The second half additionally suggests too few data points as input to the convolutional network and the clustering algorithm, which ultimately decides the outcome.
At a distance of $2.2 m$ we still find good results in a reasonable range around the robot, which we can use to evaluate a three hour long recording of the same corridor. We find the confusion matrix in Table \ref{tab:truth}, omitting false and true negatives as the sensor recorded only a specific wall in that range as negative data, making the input redundant. The long recording shows how well the network reacts to more arbitrary data, most importantly the accuracy is still high, which we can compare against the state of the art leg detector.

\begin{figure}
	\normalsize
	\begin{center}
		\input{figures/radius_detection.pgf}
	\end{center}
	\caption{\textbf{Distance dependency of the leg detector.} The diagram shows accuracies of the leg detection as a function of the number of points in a range around the laser scanner, which were counted on a frame-by-frame basis.}
	\label{fig:radius_detection}
\end{figure}

\begin{table}[]
	\def \confa {121199}
	\def \confb {19415}
	\FPeval{\confar}{round((1-\confb/\confa)*100,1)}
	\FPeval{\confbr}{round((\confb/\confa)*100,1)}
	\def \confc {4}
	\def \confd {18177714}
	\FPeval{\confcr}{round(1-\confd/\confc,1)}
	\FPeval{\confdr}{round(\confd/\confc,1)}
	\centering
	\caption{Leg detection in a radius of $2.2 m$.}
	\label{tab:truth}
	\begin{tabular}{|l|l|l|l|}
	\hline
 & \multicolumn{2}{c}{Detected Label} &  \\ \hline
 True Label & Leg & Non-Leg & Total \\ \hline
 Leg & \textbf{\confa} ($\confar \%$) & \textbf{\confb} ($\confbr \%$) & \textbf{11750} \\
 %No Leg & \textbf{\confc} ($0.0 \%$) & \textbf{\confd} ($100.0 \%$) & \textbf{292348} \\
 \hline
	\end{tabular}
\end{table}

\subsection{People detection using clusters}

Detecting people from the output of the laser classification is achieved by clustering the results as explained in section \ref{subs:clustering}. We compare the detection to the algorithm provided in the official ROS-repository\footnote{http://wiki.ros.org/leg\_detector} based on the paper of Arras et. al.\cite{Arras07usingboosted}, which uses a kalman filter to detect people and an Adaboost algorithm to label laser points. A ten second long exposure from the corridor data was hand-labeled and compared to the outputs of the programs. Due to the dependency on the distance to the scanner, different radii were considered. We find the parameters:
\begin{itemize}
	\item \textbf{True positives} ($TP$):\\The people that were detected correctly,
	\item \textbf{False positives} ($FP$):\\Non-human objects classified as people,
	\item \textbf{False negatives} ($FN$):\\People that were not detected,
\end{itemize}
which are combined into the $F-Measure$, separating good results (close to $1$) from bad results (close to $0$).
\begin{equation}
	F=\frac{2*Precision*Recall}{Precision+Recall} \in \left[ 0,1 \right]
\end{equation}
with
\begin{equation}
	Precision = \frac{TP}{TP + FP}\\
\end{equation}
\begin{equation}
	Recall = \frac{TP}{TP + FN}
\end{equation}

\begin{figure}
	\normalsize
	\begin{center}
		\input{figures/people_det.pgf}
	\end{center}
	\caption{\textbf{Accuracy of people detection.} People detectioin was benchmarked against the official leg detector, while counting the number of people on a frame-by-frame basis. The new convolutional leg detector outperforms the official leg detector in all tests.}
	\label{fig:people_detection}
\end{figure}

The Adaboost leg detector outputs probabilites of persons and legs, therefore the threshold was adapted to compare the results in a more meaningful way. In Figure \ref{fig:people_detection} we find the detections. Especially interesting is the $Precission$, as we should not allow the robot to detect any false positives. The proposed, convoluted leg detector only starts picking up false positives after $3.4 m$, like the Adaboost leg detector with 70\% threshold. However, when comparing these two, we find a large gap in the recall, meaning that the Adaboost leg detector has a low detection rate.
Conclusively, the convoluted leg detector performs very well in regards to false positives and false negatives leading to a high $Recall$ and a high $Precission$, which can be seen in the $F-Measure$.


\subsection{Trajectory prediction}

From the high accuracy of the people detection, we can extract positions to learn to predict trajectories. A benchmark has not been performed, although we can find the results as images in Figure \ref{fig:trajectory_pred}. As the output of the network is a mixture of normal distributions, the prediction program can extract the most likely positions in order to find future locations of people.

The model works well in this application and can be used to follow people, and evade incoming persons. \todo{blah blah blah, will say more once the training is finally finished}